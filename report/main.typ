#import "@preview/curryst:0.5.1": rule, prooftree

#set page(paper: "a4", numbering: "1")

#align(center)[
               #v(24pt)
               #text(size: 1.25em)[= Compiling Linear Sax to WASM]
               #v(16pt)
               CMU CS 15-817: HOT Compilation \
               Mikail Khan
               #v(16pt)
]

#align(center)[== Abstract]

Sax is an intermediate representation (IR) that helps bridge the gap between
high level, richly typed languages and lower level imperative execution.
WebAssembly (WASM) is a bytecode instruction set focused on speed, security, and portability.
It is an appealing compilation target because it can be run quickly and securely
on many platforms, including embedded devices and web browsers, and is used
in industry for accelerating web performance or running untrusted code. In this paper,
I detail the structure and implementation of a Sax to WASM compiler, supporting purely linear
types and 32-bit integers.

#v(8pt)

#set heading(numbering: "1.1")

= Introduction

The most interesting aspect of compiling linear Sax to WASM is memory management.
WASM is lower-level than Sax and exposes details like stack and local layout, so
when starting this project I spent a lot of time and effort trying to optimize these.
However, WASM runtimes often include JIT compilers that make precise stack and local layout
irrelevant to performance. Additionally, `wasm-opt` is a CLI tool and library that runs
many optimization passes, including local allocation. So the main focus of this compiler
is on exploiting linear typing's advantages for memory allocation, with an eye on maintaining
extensibility for supporting adjoint Sax through WASM GC.

The variant of Sax implemented by this compiler is a modified version of the core linear, positive
fragment introduced in Lab 1, with two additions. First, it supports 32-bit signed integers,
leveraging WASM's i32 type. It also supports closures. Both of these types are always unrestricted,
supporting all structural rules. Units are also unrestricted.

The performance of a compiler targeting WASM largely depends on the source language. Manually memory-managed
languages like C or Rust are often only 20-40% slower through WASM, while more dynamic languages like OCaml
or Scala can be 3-8x slower (no sources). Thus, the upper performance bound for linear Sax compiled to WASM 
should be similar to the performance of C compiled to WASM.

== WASM Structure

The structure and interpretation of WASM programs is largely similar to that of well-known 
instruction sets like x86 or Java bytecode, with the major difference that all its control flow is
structured. It is primarily a stack VM; instructions operate on some combination of
bytecode immediates and stack operands. There are no stack manipulation instructions.
Instead, there is a per-function set of local values which can be accessed through static
indices, emulating registers.

WASM also supports both a manually managed heap and a garbage collector.

== WASM Runtimes

There are many different WASM runtimes. The most common are browser engines like Chrome's V8 and Safari's JavaScript Core,
however, there are a variety of WASM runtimes aimed at non-web usage. In particular, I chose a runtime called Wasmtime to evaluate the compiler.

WASM does not specify a system-level interface for I/O on its own. Instead, it supports a robust foreign-function interface,
through which it requires WASM Runtimes to inject I/O functions. There is a proposal for a standardized WASM system interface
called WASI which is gaining support in major runtimes. However, it is not well documented so I opted to embed custom I/O functions
in the runtime. Thus, there is a small amount of code which is not runtime agnostic, for now.

Wasmtime is a popular and well-supported runtime focused on secure embedding. It is built as a JIT compiler on top of the Cranelift 
code generator, which is similar to LLVM but optimized for compilation speed rather than generating optimal code. It already supports
WASI, and can be used through a Rust crate. The WASM files generated by this compiler must be run through a small Rust program which
injects I/O functions and runs Wasmtime.

== Integers

To achieve competetive performance on real programs, I supplement Sax with a native 32-bit integer type.
The only changes to sax are the built-in `int` type and a few built-in metavariables used through Sax's existing
`call` command. The supported builtins are as follows:

- `call _const_{n} dest`: parses the integer out of the metavariable name and writes it to `dest`
- `call _add_ dest l r`: writes `(i32.add l r)` to `dest`
- `call _sub_ dest l r`: writes `(i32.sub l r)` to `dest`
- `call _eqz_ dest n`: writes `(i32.eqz n)` to `dest`
    - In WASM, `(i32.eqz n)` pushes `1` when `n` is zero, and `0` otherwise.
    - I did not add a builtin boolean type to Sax. Instead, this just pushes
      a sum tag with a unit injection. It makes the most sense when used with
      a type like `+{ 'false : 1, 'true : 1 }`, but is not checked.

@sum_tailrec shows a simple example of using integers in Sax.
#figure(
```
proc sum_tailrec (d : int) (n : int) (acc : int) =
    cut tst : bool
        call _eqz_ tst n
    read tst {
    | 'true(u) =>
        id d acc
    | 'false(u) => cut n1 : int
                       cut one : int
                           call _const_1 one
                       call _sub_ n1 n one
                   cut nxt : int
                       call _add_ nxt acc n
                   call sum_tailrec d n1 nxt
    }
```,
caption: [`sum_tailrec(n, acc)` = $sum(0..n) + "acc"$],
kind: "example",
supplement: "Example"
) <sum_tailrec>

== Compilation Stages and Execution

The compiler and runtime have several components. First, the compiler
does a simple pass over the Sax, generating a simple stack-based sequential IR
and doing a simple static analysis. Then, it does another pass over the stack-based IR
to generate WASM instructions. Finally, the compiler expects the WASM module to be optimized by
`wasm-opt`. It should not be strictly necessary, but there seem to be differences in how Wasmtime 
and `wasm-opt` validate modules, so output directly from the compiler often does not run in Wasmtime 
without using `wasm-opt` first.

Unlike the Sax compiler from class, this compiler requires a `main` proc, with a destination
of any type. The runner will find the main proc and print its output.

== Limitations

There are some limitations driven by time constraints, but they should be fixable without
modifying the whole approach.

- The main proc is limited
    - Its return type must be a typename because of how printing works, as described below
    - It does not support Read, because of how the print call is injected
- Subtyping probably has bugs
    - the compiler assumes that all instances of a type have the same layout,
      but does not enforce this on downcasts
- Memory does not grow
    - the allocator does not ever grow the memory, so it is limited to one WASM page of 64 KiB.

= Implementation

The translation from Sax to WASM is guided by a few principles. First, the destination of the
current translated command is just the top of the stack. Thus, translating a metavariable writing
to destination `d` results in a sequence of WASM instructions that result in `d` on the top of the
stack.

The translation from the stack IR to WASM carefully tracks the stack and locals. In particular, it tries
to track the relationship between different variables, in order to accurately locate them in cases where a
stack value may represent both a variable and e.g. the left pi of a pair.
I believe this approach is convoluted and could be simplified by taking advantage of properties of the initial
translation from Sax to the stack IR. I designed it when I was trying to optimize exact stack and local layout.

Possible stack values are as follow:
- `Addr s`: an address bound to variable `s`
- `GcRef s`: a GC'd reference bound to variable `s`
- `InjTag s`: the tag of plus-type variable `s`
- `InjData s`: the injection of plus-type variable `s`
- `PairFst s`: the $pi_1$ of pair-type variable `s`
- `PairSnd s`: the $pi_2$ of pair-type variable `s`
- `Unit s`: a unit bound to variable `s`
    - These never actually materialize in WASM, and are instead used to pad with zero consts when needed
- `Int s`: an integer bound to variable `s`
    - Integers are passed by value

The basic translation judgement is:

$ S_I ⊢ [| c |] = (W ; S_O) $

meaning that translating Sax command $c$ with abstract stack $S_I$ yields 
a list of WASM instructions $W$ and a stack representation $S_O$. Our rules will be used pretty
informally, and leave out some info about state. It leaves skips stack IR step, so there are some slight differences from the code.

== Allocation and Value Layout

The layout of values is the same on the stack and heap. Cells are always represented as two `i32`s.
They may be a pair of primitives, or a primitive followed by a tag, where the primitives could represent
an address, unit, or integer.

Since all cells are the same size, our allocator is very simple. We keep an implicit freelist, where
the first value of a freed cell is the offset to the next cell. There are two functions:
- `alloc(v1: i32, v2: i32)` writes `v1` and `v2` to the cell on top of the freelist, bumps the 
  freelist pointer by the offset previously written to the cell, and returns the address allocated.
- `free(addr: i32)` writes the current freelist head to the front of the cell, and sets the new freelist
   pointer to `addr`.

I made some strange choices in this design. First, I opted to start the freelist with every allocated
cell by writing an offset of 8 to every cell on initialization. This saves storing an additional pointer
to space that has yet to be allocated or freed, but is probably slower when memory is resized. Additionally,
I wrote the allocator in Rust, embedding it into the runtime, instead of using WASM's built-in memory instructions.
This was just done to save myself from writing WASM by hand. It makes the generated code less portable, but
is likely a little bit faster, since the Rust code is not subject to the same safety checks that WASM would have.

== Cuts and Locals

Using our invariants the cut translation is pretty straightforward. Since the destination 
of any command is the top of the stack, we know that the cut variable will be on top,
either as components as a single address. With our stack representation, we can differentiate each case.

The binding created by cut should be randomly accessible by the second command, so we greedily make 
a local for each cut in case it is not on top of the stack when needed. This creates a lot of churn
and local rewriting but `wasm-opt` handles it.

If the top of the stack after the first command is already an address, our translation just creates a local for it.
If it is a decomposed cell of an injection tag and value or pair components, we allocate them and then push
the address to our locals.

$
    #prooftree(rule(
        name: [$"Cut"_"addr"$],
        [$S ⊢ [| bold("cut") (x : T) P(x) Q(x) |] = W_P :: bold("local.set ")n :: W_Q ; S_Q $],
        [$S ⊢ [| P |] = W_P ; "Addr x" :: S_P $],
        [$S_P ⊢ [| Q |] = W_Q ; S_Q$]
    ))
$
$
    #prooftree(rule(
        name: [$"Cut"_"pair"$],
        [$S ⊢ [| bold("cut") (x : T) P(x) Q(x) |] = W_P :: bold("call") "alloc" :: bold("local.set ")n :: W_Q ; S_Q $],
        [$S ⊢ [| P |] = W_P ; ⋄ :: ⋄ :: S_P $],
        [$S_P ⊢ [| Q |] = W_Q ; S_Q$]
    ))
$

Note that $"Cut"_"pair"$ applies to both pairs and injections, or even pairs of addresses where the top
address is not the destination.

== Read

Read commands dereference and free an address, put its components into locals, and then build a switch
if there are multiple cases.

$
    #prooftree(rule(
        name: [$"Read"_"Pair"$],
        [$S ⊢ [| bold("read") s" "(l, r)" "c |] = "DerefPair"(L_s) :: W_C ; S_C $],
        [$ S ⊢ [| c |] = W_C; S_C $]))
$
$
    "DerefPair"(L_s) =& bold("local.get") L_s :: bold("memory.load") :: bold("local.set") L_(s_(pi_1)) \
                    ::& bold("local.get") L_s :: bold("memory.load") "offset="4 :: bold("local.set") L_(s_(pi_2)) \
                    ::& bold("local.get") L_s :: bold("call") "free" ; S
$

== Write

Write commands move something onto the top of the stack.
$
    #prooftree(rule(
        name: [$"Write"_"Unit"$],
        [$S ⊢ [| bold("write") d" "() |] = bold("i32.const") 0 ; () :: S$],
    ))
$

$
    #prooftree(rule(
        name: [$"Write"_"Pair"$],
        [$S ⊢ [| bold("write") d" "(pi_1,pi_2) |] = bold("local.get") L_(pi_1) :: bold("local.get") L_(pi_2); "PairFst d" :: "PairSnd d" :: S$],
    ))
$

$
    #prooftree(rule(
        name: [$"Write"_"Plus"$],
        [$S ⊢ [| bold("write") d" " \'l(a) |] = bold("local.get") a :: bold("i32.const") T; "InjTag d" :: "InjData d" :: S$],
    ))
$

== Calls and Tail Calls

The call translation is straightforward.
$
    #prooftree(rule(
        name: [Call],
        [$S ⊢ [| bold("call") p" "d" "a_1 ... a_n |] = bold("local.get") L_(a_1) ... L_(a_n) :: bold("call") p; "Addr d" :: S $],
    ))
$

Sax's only iteration construct is recursion. To avoid stack-overflows, we need to properly tail
recurse on tail-recursive Sax functions. This is straightforward using WASM's tail call proposal,
which has been merged and is supported by most runtimes. However, I found that it is still a bit
slow in Wasmtime.

To detect when a tall is a tail-call, we just check if the destination of a call is the destination
of the whole function. Then, it suffices to replace the WASM `call` instruction with `return_call`.

== Id

Id is similar to Write. We just need to ensure that the required address is on top of the stack; there are two
cases. If it is already on top, we continue, otherwise we must fetch it from our locals.

== Closures

Closures are garbage collected. There are some considerations to make about adjoint Sax,
since all closures are currently unrestricted. GC references can not be stored on the heap,
so linear data cannot reference unrestricted closures, but we can still store heap references
in the GC. This aligns with adjoint Sax's mode preorder restriction.

#lorem(40)

== Printing

Printing is a little complicated. Since tags are indexed by type, we need the full type of an object
to print it. It would be possible to generate a print function for each type, but I instead opted
to write a single print function in Rust which accepts the type index as a parameter. To do so,
we must serialize every type def so that it is accessible to the runtime. The compiler uses
yojson to serialize the type defs to JSON, and then exports it to the runtime using WASM's
data segments. This undoubtedly makes printing pretty slow.

== Optimizations

We implement a few optimizations, mostly aimed at minimizing allocations.

=== Unboxed Cut/Read

If the variable instantiated by a cut is read in the same function, we skip allocating it.
Instead, we put its components in locals. This modifies the translation rules for Cut and Read.

=== Cut/Id

The simple Cut/Id optimization is implicit through our translation of Id. 

=== Vertical Reuse

Though we could easily implement vertical reuse in the compilation, it might be interesting
to note that it the allocator design replicates this behavior, since the freelist is essentially
a stack and the most recently freed cells are the next allocated ones. Implementing it through
the compiler would save some freelist manipulation but the performance gain might be quite small.

=== Future Work: Lazily allocating function returns

Currently, cuts within a function are not allocated if they are Read within the function. It might
make sense to let all functions return without allocating first, so the caller can decide not to
allocate if the return is Read.

#lorem(40)

= Evaluation

Holistically, the generated code looks good. The optimizations catch many overaggressive allocations,
and `wasm-opt` minimizes stack and local manipulation.

TODO: some examples

== Benchmarks

#lorem(60)

== Iteration and Tail Calls

Despite using WASM's native tail calls, iteration speed is pretty slow. For the `sum_tailrec`
function in @sum_tailrec  the compiler generates pretty idiomatic recursive WASM below. 
After hand-translating it to a loop, it becomes around 10x faster for summing the first billion integers.

#figure(
```wat
 (func $sum_tailrec (param $0 i32) (param $1 i32) (result i32)
  (if (local.get $0)
   (then (return_call $8 
         (i32.sub (local.get $0) (i32.const 1))
         (i32.add (local.get $0) (local.get $1)))))
  (local.get $1))
```,
caption: [compiled `sum_tailrec`, tail recursive],
kind: "example",
supplement: "Example"
) <sum_tailrec_rec>

#figure(
```wat
(func $sum_loop (param $0 i32) (param $1 i32) (result i32)
  (block $done
    (loop $continue
      (br_if $done (i32.eqz (local.get $0)))
      (local.set $1 (i32.add (local.get $0) (local.get $1)))
      (local.set $0 (i32.sub (local.get $0) (i32.const 1)))
      (br $continue)))
  (local.get $1))
```,
caption: [compiled `sum_tailrec`, loop],
kind: "example",
supplement: "Example"
) <sum_tailrec_rec>

This is probably runtime dependent, and might be fixed by a Wasmtime update. However, a more robust 
compiler might want to turn some recursive functions into loops.

= Related Work

#lorem(240)

= Conclusion

#lorem(120)

== Future Work
